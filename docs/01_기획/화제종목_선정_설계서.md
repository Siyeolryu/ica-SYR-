# 미국 주식 "오늘의 화제 종목" 선정 설계서

## 1. 각 데이터 소스의 장단점 비교

### 1.1 yahooquery Screener

#### 장점
- **실시간 데이터 제공**: Yahoo Finance의 실시간 시장 데이터를 직접 활용
- **객관적 지표 기반**: 거래량, 상승률 등 정량적 데이터로 신뢰성 높음
- **다양한 스크리너 옵션**: 
  - `most_actives`: 거래량 상위 종목 (시장 관심도 측정)
  - `day_gainers`: 당일 상승률 상위 (급등주 포착)
  - `day_losers`: 당일 하락률 상위 (변동성 큰 종목 파악)
- **Python 라이브러리 지원**: `yahooquery` 패키지로 간편한 API 호출
- **무료 사용 가능**: 별도 API 키 불필요
- **안정적인 데이터 소스**: Yahoo Finance는 오래된 신뢰할 수 있는 데이터 제공자

#### 단점
- **API 호출 제한**: 과도한 요청 시 IP 차단 가능성
- **데이터 지연**: 일부 데이터는 실시간이 아닐 수 있음 (보통 15-20분 지연)
- **제한적인 커스터마이징**: Yahoo Finance가 제공하는 스크리너 옵션에 제한됨
- **소셜 미디어 트렌드 미반영**: Reddit, 트위터 등 소셜 미디어 화제도는 반영 안 됨

### 1.2 ApeWisdom (apewisdom.io)

#### 장점
- **소셜 미디어 트렌드 반영**: Reddit WallStreetBets(WSB) 커뮤니티 멘션 순위 제공
- **조기 신호 포착**: 소셜 미디어에서 먼저 화제가 된 종목을 빠르게 파악 가능
- **24시간 멘션 추적**: 실시간으로 언급 빈도 모니터링
- **무료 API 제공**: 기본적인 데이터는 무료로 접근 가능

#### 단점
- **특정 커뮤니티 한정**: WSB에만 집중되어 있어 시장 전체 동향 반영 어려움
- **데이터 신뢰성 문제**: 멘션 수가 실제 거래량과 비례하지 않을 수 있음
- **API 안정성**: 무료 서비스의 경우 다운타임이나 제한 가능성
- **감성 분석 부재**: 단순 멘션 수만 제공, 긍정/부정 구분 없음
- **스팸/봇 영향**: 인위적인 멘션 증가 가능성

### 1.3 SwaggyStocks

#### 장점
- **감성 분석 제공**: WSB의 긍정적/부정적 감성 분석 가능
- **실시간 모니터링**: 실시간으로 감성 변화 추적
- **시각화 데이터**: 차트와 그래프로 직관적인 정보 제공
- **트렌드 예측**: 감성 분석을 통한 잠재적 움직임 예측 가능

#### 단점
- **WSB 커뮤니티 한정**: ApeWisdom과 동일한 한계
- **감성 분석 정확도**: 자연어 처리의 한계로 인한 오분류 가능성
- **API 접근성**: 무료 API 제공 여부 불확실, 스크래핑 필요할 수 있음
- **데이터 소스 의존성**: Reddit API 정책 변경에 취약

## 2. 권장 데이터 소스 선정 및 근거

### 2.1 주요 데이터 소스: yahooquery Screener

**선정 근거:**

1. **객관성과 신뢰성**
   - 거래량과 상승률은 실제 시장 활동을 반영하는 객관적 지표
   - Yahoo Finance는 오랜 기간 검증된 데이터 제공자

2. **서비스 목적과의 부합**
   - "가장 활발한 종목" 선정 목적에 가장 적합
   - 거래량(`most_actives`)과 상승률(`day_gainers`) 조합으로 화제도 측정 가능

3. **기술적 안정성**
   - 공식 Python 라이브러리 제공으로 안정적인 통합 가능
   - API 호출 제한만 관리하면 지속적 사용 가능

4. **유지보수 용이성**
   - 단일 데이터 소스로 시스템 복잡도 감소
   - 외부 의존성 최소화

### 2.2 보조 데이터 소스 (선택적): ApeWisdom

**활용 방안:**
- 소셜 미디어 트렌드가 중요한 경우 보조 지표로 활용
- yahooquery 데이터와 교차 검증
- 초기 단계에서는 제외하고, 향후 고도화 시 추가 고려

### 2.3 최종 권장안

**1차 개발**: yahooquery Screener만 사용
- 빠른 개발 및 안정적인 서비스 제공
- 핵심 가치 제안 충족

**2차 고도화**: ApeWisdom 추가 (선택적)
- 소셜 미디어 트렌드 반영으로 차별화
- 종합 점수 산정 시 가중치 부여

## 3. yahooquery Screener 사용 코드 예시

### 3.1 기본 설치 및 임포트

```python
# 설치: pip install yahooquery
from yahooquery import Screener
import pandas as pd
from typing import List, Dict, Optional
import logging
from datetime import datetime

# 로깅 설정
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
```

### 3.2 스크리너 데이터 수집 함수

```python
def get_screener_data(
    screener_types: List[str] = ['most_actives', 'day_gainers'],
    count: int = 10
) -> Dict[str, List[Dict]]:
    """
    Yahoo Finance Screener에서 종목 데이터를 수집합니다.
    
    Args:
        screener_types: 수집할 스크리너 타입 리스트
        count: 각 스크리너에서 가져올 종목 수
    
    Returns:
        스크리너 타입별 종목 리스트를 담은 딕셔너리
    """
    try:
        screener = Screener()
        screeners = screener.get_screeners(screener_types, count=count)
        
        result = {}
        for screener_type, data in screeners.items():
            if 'quotes' in data:
                result[screener_type] = data['quotes']
                logger.info(f"{screener_type}: {len(data['quotes'])}개 종목 수집 완료")
            else:
                logger.warning(f"{screener_type}: 데이터 없음")
                result[screener_type] = []
        
        return result
    
    except Exception as e:
        logger.error(f"스크리너 데이터 수집 실패: {str(e)}")
        return {screener_type: [] for screener_type in screener_types}
```

### 3.3 종목 정보 정리 함수

```python
def normalize_stock_data(screener_data: Dict[str, List[Dict]]) -> pd.DataFrame:
    """
    스크리너 데이터를 정규화하여 DataFrame으로 변환합니다.
    
    Args:
        screener_data: get_screener_data()의 반환값
    
    Returns:
        정규화된 종목 정보 DataFrame
    """
    stocks = []
    
    for screener_type, quotes in screener_data.items():
        for quote in quotes:
            stock_info = {
                'symbol': quote.get('symbol', ''),
                'name': quote.get('shortName', quote.get('longName', '')),
                'volume': quote.get('regularMarketVolume', 0),
                'change_percent': quote.get('regularMarketChangePercent', 0),
                'price': quote.get('regularMarketPrice', 0),
                'market_cap': quote.get('marketCap', 0),
                'screener_type': screener_type,
                'timestamp': datetime.now()
            }
            stocks.append(stock_info)
    
    df = pd.DataFrame(stocks)
    
    # 중복 제거 (동일 종목이 여러 스크리너에 포함된 경우)
    df = df.drop_duplicates(subset=['symbol'], keep='first')
    
    return df
```

### 3.4 전체 데이터 수집 예시

```python
# 사용 예시
if __name__ == "__main__":
    # 1. 스크리너 데이터 수집
    screener_data = get_screener_data(
        screener_types=['most_actives', 'day_gainers'],
        count=10
    )
    
    # 2. 데이터 정규화
    df = normalize_stock_data(screener_data)
    
    # 3. 결과 확인
    print(f"\n총 {len(df)}개 종목 수집")
    print("\n상위 5개 종목:")
    print(df[['symbol', 'name', 'volume', 'change_percent']].head())
```

## 4. TOP 1 종목 선정 로직

### 4.1 점수 계산 알고리즘

화제 종목 선정을 위해 다음과 같은 점수 계산 방식을 제안합니다:

```python
def calculate_trending_score(
    df: pd.DataFrame,
    volume_weight: float = 0.6,
    change_weight: float = 0.4
) -> pd.DataFrame:
    """
    종목의 화제도 점수를 계산합니다.
    
    Args:
        df: normalize_stock_data()의 반환값
        volume_weight: 거래량 가중치 (기본값: 0.6)
        change_weight: 상승률 가중치 (기본값: 0.4)
    
    Returns:
        score 컬럼이 추가된 DataFrame
    """
    df = df.copy()
    
    # 정규화: 0-1 범위로 스케일링
    max_volume = df['volume'].max()
    max_change = df['change_percent'].abs().max()
    
    if max_volume > 0:
        df['normalized_volume'] = df['volume'] / max_volume
    else:
        df['normalized_volume'] = 0
    
    if max_change > 0:
        df['normalized_change'] = df['change_percent'].abs() / max_change
    else:
        df['normalized_change'] = 0
    
    # 가중 평균 점수 계산
    df['score'] = (
        df['normalized_volume'] * volume_weight +
        df['normalized_change'] * change_weight
    )
    
    return df
```

### 4.2 TOP 1 종목 선정 함수

```python
def select_top_trending_stock(
    df: pd.DataFrame,
    min_volume: Optional[int] = None,
    min_change_percent: Optional[float] = None
) -> Optional[Dict]:
    """
    화제도 점수가 가장 높은 종목을 선정합니다.
    
    Args:
        df: calculate_trending_score()의 반환값
        min_volume: 최소 거래량 필터 (선택)
        min_change_percent: 최소 상승률 필터 (선택)
    
    Returns:
        TOP 1 종목 정보 딕셔너리 또는 None
    """
    df_filtered = df.copy()
    
    # 필터 적용
    if min_volume is not None:
        df_filtered = df_filtered[df_filtered['volume'] >= min_volume]
    
    if min_change_percent is not None:
        df_filtered = df_filtered[
            df_filtered['change_percent'] >= min_change_percent
        ]
    
    # 데이터가 없는 경우
    if len(df_filtered) == 0:
        logger.warning("필터 조건을 만족하는 종목이 없습니다.")
        return None
    
    # 점수 기준 정렬 후 TOP 1 선택
    df_sorted = df_filtered.sort_values('score', ascending=False)
    top_stock = df_sorted.iloc[0].to_dict()
    
    logger.info(
        f"TOP 1 종목 선정: {top_stock['symbol']} "
        f"({top_stock['name']}) - 점수: {top_stock['score']:.4f}"
    )
    
    return top_stock
```

### 4.3 통합 실행 함수

```python
def get_today_trending_stock(
    screener_types: List[str] = ['most_actives', 'day_gainers'],
    count: int = 10,
    volume_weight: float = 0.6,
    change_weight: float = 0.4,
    min_volume: Optional[int] = None,
    min_change_percent: Optional[float] = None
) -> Optional[Dict]:
    """
    오늘의 화제 종목을 선정하는 통합 함수입니다.
    
    Args:
        screener_types: 사용할 스크리너 타입 리스트
        count: 각 스크리너에서 가져올 종목 수
        volume_weight: 거래량 가중치
        change_weight: 상승률 가중치
        min_volume: 최소 거래량 필터
        min_change_percent: 최소 상승률 필터
    
    Returns:
        TOP 1 종목 정보 또는 None
    """
    try:
        # 1. 데이터 수집
        screener_data = get_screener_data(screener_types, count)
        
        # 2. 데이터 정규화
        df = normalize_stock_data(screener_data)
        
        if len(df) == 0:
            logger.error("수집된 종목 데이터가 없습니다.")
            return None
        
        # 3. 점수 계산
        df_scored = calculate_trending_score(df, volume_weight, change_weight)
        
        # 4. TOP 1 선정
        top_stock = select_top_trending_stock(
            df_scored,
            min_volume,
            min_change_percent
        )
        
        return top_stock
    
    except Exception as e:
        logger.error(f"화제 종목 선정 실패: {str(e)}")
        return None

# 사용 예시
if __name__ == "__main__":
    top_stock = get_today_trending_stock(
        screener_types=['most_actives', 'day_gainers'],
        count=10,
        volume_weight=0.6,
        change_weight=0.4
    )
    
    if top_stock:
        print(f"\n오늘의 화제 종목:")
        print(f"심볼: {top_stock['symbol']}")
        print(f"이름: {top_stock['name']}")
        print(f"거래량: {top_stock['volume']:,}")
        print(f"변동률: {top_stock['change_percent']:.2f}%")
        print(f"화제도 점수: {top_stock['score']:.4f}")
```

## 5. 엣지 케이스 처리

### 5.1 데이터 없음 처리

```python
def handle_empty_data(screener_data: Dict[str, List[Dict]]) -> bool:
    """
    수집된 데이터가 비어있는지 확인하고 처리합니다.
    
    Returns:
        데이터가 유효하면 True, 아니면 False
    """
    total_count = sum(len(quotes) for quotes in screener_data.values())
    
    if total_count == 0:
        logger.warning("모든 스크리너에서 데이터를 수집하지 못했습니다.")
        # 대체 로직: 이전 데이터 사용 또는 기본 종목 반환
        return False
    
    return True

# 개선된 get_screener_data 함수
def get_screener_data_with_retry(
    screener_types: List[str],
    count: int,
    max_retries: int = 3
) -> Dict[str, List[Dict]]:
    """재시도 로직이 포함된 데이터 수집 함수"""
    for attempt in range(max_retries):
        try:
            screener_data = get_screener_data(screener_types, count)
            
            if handle_empty_data(screener_data):
                return screener_data
            
            if attempt < max_retries - 1:
                logger.info(f"재시도 {attempt + 1}/{max_retries}")
                time.sleep(2 ** attempt)  # 지수 백오프
        
        except Exception as e:
            logger.error(f"시도 {attempt + 1} 실패: {str(e)}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
    
    return {screener_type: [] for screener_type in screener_types}
```

### 5.2 중복 종목 처리

```python
def handle_duplicates(df: pd.DataFrame, strategy: str = 'first') -> pd.DataFrame:
    """
    중복 종목을 처리합니다.
    
    Args:
        df: 종목 데이터 DataFrame
        strategy: 중복 처리 전략
            - 'first': 첫 번째 항목 유지
            - 'highest_score': 점수가 높은 항목 유지
            - 'merge': 여러 스크리너 정보 병합
    
    Returns:
        중복이 제거된 DataFrame
    """
    if strategy == 'first':
        return df.drop_duplicates(subset=['symbol'], keep='first')
    
    elif strategy == 'highest_score':
        if 'score' in df.columns:
            df_sorted = df.sort_values('score', ascending=False)
            return df_sorted.drop_duplicates(subset=['symbol'], keep='first')
        else:
            logger.warning("점수 컬럼이 없어 'first' 전략으로 대체")
            return df.drop_duplicates(subset=['symbol'], keep='first')
    
    elif strategy == 'merge':
        # 여러 스크리너에 포함된 종목의 정보를 병합
        df_grouped = df.groupby('symbol').agg({
            'name': 'first',
            'volume': 'max',  # 최대 거래량
            'change_percent': 'mean',  # 평균 변동률
            'price': 'last',  # 최신 가격
            'market_cap': 'first',
            'screener_type': lambda x: ','.join(x.unique()),  # 포함된 스크리너 목록
            'timestamp': 'first'
        }).reset_index()
        
        return df_grouped
    
    else:
        logger.warning(f"알 수 없는 전략: {strategy}, 'first'로 대체")
        return df.drop_duplicates(subset=['symbol'], keep='first')
```

### 5.3 데이터 유효성 검증

```python
def validate_stock_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    종목 데이터의 유효성을 검증하고 이상치를 제거합니다.
    
    Args:
        df: 종목 데이터 DataFrame
    
    Returns:
        유효한 데이터만 포함한 DataFrame
    """
    df_valid = df.copy()
    initial_count = len(df_valid)
    
    # 필수 필드 검증
    required_fields = ['symbol', 'volume', 'change_percent']
    df_valid = df_valid.dropna(subset=required_fields)
    
    # 심볼 형식 검증 (대문자, 알파벳만)
    df_valid = df_valid[df_valid['symbol'].str.match(r'^[A-Z]+$')]
    
    # 거래량이 0보다 큰 종목만
    df_valid = df_valid[df_valid['volume'] > 0]
    
    # 변동률이 비정상적으로 큰 경우 제외 (예: 1000% 이상)
    df_valid = df_valid[df_valid['change_percent'].abs() <= 1000]
    
    removed_count = initial_count - len(df_valid)
    if removed_count > 0:
        logger.info(f"{removed_count}개 종목이 유효성 검증에서 제외되었습니다.")
    
    return df_valid
```

### 5.4 API 호출 제한 처리

```python
import time
from functools import wraps

def rate_limit(max_calls: int = 10, period: int = 60):
    """
    API 호출 제한을 관리하는 데코레이터
    
    Args:
        max_calls: 기간 내 최대 호출 수
        period: 제한 기간 (초)
    """
    calls = []
    
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            now = time.time()
            
            # 기간이 지난 호출 기록 제거
            calls[:] = [call_time for call_time in calls if now - call_time < period]
            
            # 호출 제한 확인
            if len(calls) >= max_calls:
                sleep_time = period - (now - calls[0])
                logger.warning(f"API 호출 제한 도달. {sleep_time:.1f}초 대기")
                time.sleep(sleep_time)
                calls.clear()
            
            calls.append(now)
            return func(*args, **kwargs)
        
        return wrapper
    return decorator

# 사용 예시
@rate_limit(max_calls=10, period=60)
def get_screener_data_rate_limited(screener_types, count):
    return get_screener_data(screener_types, count)
```

### 5.5 통합 엣지 케이스 처리 함수

```python
def get_today_trending_stock_robust(
    screener_types: List[str] = ['most_actives', 'day_gainers'],
    count: int = 10,
    fallback_symbol: Optional[str] = None
) -> Optional[Dict]:
    """
    엣지 케이스를 모두 처리한 견고한 화제 종목 선정 함수
    
    Args:
        screener_types: 사용할 스크리너 타입 리스트
        count: 각 스크리너에서 가져올 종목 수
        fallback_symbol: 모든 데이터 수집 실패 시 반환할 기본 종목
    
    Returns:
        TOP 1 종목 정보 또는 None
    """
    try:
        # 1. 재시도 로직 포함 데이터 수집
        screener_data = get_screener_data_with_retry(screener_types, count)
        
        # 2. 데이터 유효성 확인
        if not handle_empty_data(screener_data):
            if fallback_symbol:
                logger.info(f"기본 종목 사용: {fallback_symbol}")
                return {'symbol': fallback_symbol}
            return None
        
        # 3. 데이터 정규화
        df = normalize_stock_data(screener_data)
        
        # 4. 유효성 검증
        df = validate_stock_data(df)
        
        if len(df) == 0:
            logger.error("유효한 종목 데이터가 없습니다.")
            if fallback_symbol:
                return {'symbol': fallback_symbol}
            return None
        
        # 5. 중복 처리
        df = handle_duplicates(df, strategy='highest_score')
        
        # 6. 점수 계산
        df_scored = calculate_trending_score(df)
        
        # 7. TOP 1 선정
        top_stock = select_top_trending_stock(df_scored)
        
        return top_stock
    
    except Exception as e:
        logger.error(f"화제 종목 선정 중 오류 발생: {str(e)}")
        if fallback_symbol:
            logger.info(f"기본 종목 사용: {fallback_symbol}")
            return {'symbol': fallback_symbol}
        return None
```

## 6. 추가 고려사항

### 6.1 시간대 처리
- 미국 증시 운영 시간(EST 9:30 AM - 4:00 PM) 고려
- 한국 시간 기준 새벽에 실행 시 전일 데이터 사용

### 6.2 캐싱 전략
- 동일 시간대 중복 호출 방지를 위한 캐싱
- Redis 또는 메모리 캐시 활용

### 6.3 모니터링 및 알림
- 데이터 수집 실패 시 알림
- 점수 분포 모니터링으로 이상 탐지

---

**작성일**: 2024년
**버전**: 1.0










